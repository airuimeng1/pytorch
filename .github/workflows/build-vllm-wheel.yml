name: Build vLLM wheels

on:
  push:
    branches:
      - main
    paths:
      - .github/workflows/build-vllm-wheel.yml
      - .github/ci_commit_pins/vllm.txt
  workflow_dispatch:
  pull_request:
    paths:
      - .github/workflows/build-vllm-wheel.yml
      - .github/ci_commit_pins/vllm.txt

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  build-wheel:
    name: "Build ${{ matrix.device }} vLLM wheel"
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        python-version: [ '3.12' ]
        device: [ 'cuda' ]
        runner: linux.12xlarge
        include:
          - device: cuda
            cuda-version: cu128
            docker-image: 'pytorch/manylinux2_28-builder:cuda12.8'
          - device: cuda
            cuda-version: cu129
            docker-image: 'pytorch/manylinux2_28-builder:cuda12.9'
    timeout-minutes: 240
    env:
      PY_VERS: ${{ matrix.python-version }}
      DOCKER_IMAGE: ${{ matrix.docker-image }}
      PLATFORM: 'manylinux_2_28_x86_64'
      BUILD_DEVICE: ${{ matrix.device }}
      BUILD_VERSION: ${{ matrix.device == 'cuda' && matrix.cuda-version || '' }}
    steps:
      - name: Setup SSH (Click me for login details)
        uses: pytorch/test-infra/.github/actions/setup-ssh@main
        with:
          github-secret: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout PyTorch
        uses: pytorch/pytorch/.github/actions/checkout-pytorch@main
        with:
          submodules: false

      - name: Setup Linux
        uses: ./.github/actions/setup-linux

      - name: Pull Docker image
        uses: pytorch/test-infra/.github/actions/pull-docker-image@main
        with:
          docker-image: ${{ env.DOCKER_IMAGE }}

      - name: Get latest PyTorch nightly
        shell: bash
        run: |
          set -eux

          # Keep PyTorch nightly wheel here so that we can install it later during
          # vLLM build process
          mkdir -p "${RUNNER_TEMP}/artifacts/"

          container_name=$(docker run \
            --tty \
            --detach \
            -v "${GITHUB_WORKSPACE}:/pytorch" \
            -v "${RUNNER_TEMP}/artifacts:/artifacts" \
            -w /artifacts/ \
            "${DOCKER_IMAGE}"
          )

          # Determine python executable for given version (copied from build-triton-wheel)
          case $PY_VERS in
          3.10)
            PYTHON_EXECUTABLE=/opt/python/cp310-cp310/bin/python
            ;;
          3.11)
            PYTHON_EXECUTABLE=/opt/python/cp311-cp311/bin/python
            ;;
          3.12)
            PYTHON_EXECUTABLE=/opt/python/cp312-cp312/bin/python
            ;;
          3.13)
            PYTHON_EXECUTABLE=/opt/python/cp313-cp313/bin/python
            ;;
          3.13t)
            PYTHON_EXECUTABLE=/opt/python/cp313-cp313t/bin/python
            ;;
          3.14)
            PYTHON_EXECUTABLE=/opt/python/cp314-cp314/bin/python
            ;;
          3.14t)
            PYTHON_EXECUTABLE=/opt/python/cp314-cp314t/bin/python
            ;;
          *)
            echo "Unsupported python version ${PY_VERS}"
            exit 1
            ;;
          esac

          docker exec -t "${container_name}" "${PYTHON_EXECUTABLE}" -mpip download \
            --pre torch \
            --index-url https://download.pytorch.org/whl/nightly/"${BUILD_VERSION}"

      - name: Build vLLM wheel
        uses: ./.github/actions/build-external-packages
        with:
          build-targets: vllm
          docker-image: ${{ matrix.docker-image }}
          cuda-arch-list: '8.0;8.9;9.0'
          torch-wheel-dir: ${{ runner.temp }}/artifacts
          output-dir: ${{ runner.temp }}/externals

      - uses: actions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874 # v4.4.0
        with:
          name: vllm-wheel-${{ matrix.py_vers }}-${{ matrix.device }}-${{ env.BUILD_VERSION }}-${{ env.PLATFORM }}
          if-no-files-found: error
          path: ${{ runner.temp }}/externals/vllm/*

      - name: Teardown Linux
        uses: pytorch/test-infra/.github/actions/teardown-linux@main
        if: always()
